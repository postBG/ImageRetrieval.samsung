{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "773afacd",
   "metadata": {},
   "source": [
    "# Towards Content-based Image Retrieval Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eb38d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext ipython_unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "115a99e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import unittest\n",
    "import numpy as np\n",
    "import utils\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torchvision import datasets, transforms\n",
    "from utils import ImageHelper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9812419c",
   "metadata": {},
   "source": [
    "## Dataset: fashionMNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b214ec61",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eda52ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 32\n",
    "mean = (0.5,)\n",
    "std = (0.5,)\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.Resize((img_size, img_size)), \n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=mean, std=std)])\n",
    "image_helper = ImageHelper(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43976936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import FashionMNIST\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "trainset = FashionMNIST('./data', download=True, split='train', transform=transform)\n",
    "valset = FashionMNIST('./data', download=True, split='val', transform=transform)\n",
    "testset = FashionMNIST('./data', download=True, split='test', transform=transform)\n",
    "\n",
    "idx_to_class = trainset.idx_to_class\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde9cdd5",
   "metadata": {},
   "source": [
    "### Take a Look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87082f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
      "{0: 'T-shirt/top', 1: 'Trouser', 2: 'Pullover', 3: 'Dress', 4: 'Coat', 5: 'Sandal', 6: 'Shirt', 7: 'Sneaker', 8: 'Bag', 9: 'Ankle boot'}\n",
      "train dataset size: 54000\n",
      "validation dataset size: 6000\n",
      "test dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "print(trainset.classes)\n",
    "print(idx_to_class)\n",
    "print(f'train dataset size: {len(trainset)}')\n",
    "print(f'validation dataset size: {len(valset)}')\n",
    "print(f'test dataset size: {len(testset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b8c2f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: Dress\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label, idx = trainset[3]\n",
    "image_helper.show_img(img)\n",
    "print(f'label: {trainset.idx_to_class[label]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3edd7d",
   "metadata": {},
   "source": [
    "## Database & kNN Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e21cc3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class Database(object):\n",
    "    def __init__(self, dataloader, feature_extractor):\n",
    "        self.dataloader = dataloader\n",
    "        self.dataset = dataloader.dataset\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.images_indices, self.extracted_features, self.targets = self.extract_features_to_construct_database()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def extract_features_to_construct_database(self):\n",
    "        self.feature_extractor.eval()\n",
    "        all_indices = []\n",
    "        all_features = []\n",
    "        all_targets = []\n",
    "        for xs, ys, idxs in tqdm(self.dataloader):\n",
    "            features = self.feature_extractor(xs)\n",
    "            features = features.view(features.size(0), -1)\n",
    "            all_features.extend(features)\n",
    "            \n",
    "            all_indices.extend(idxs)\n",
    "            all_targets.extend(ys)\n",
    "        return torch.stack(all_indices), torch.stack(all_features), torch.stack(all_targets)\n",
    "    \n",
    "    def get_image_and_target(self, idx):\n",
    "        return self.dataset[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960b674b",
   "metadata": {},
   "source": [
    "### Practice 1: Implement k-nearest neighbor algorithm\n",
    "\n",
    "We will use the dot-product between two vectors as the distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aaf3976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN_search(query: torch.Tensor, database: Database, k=10):\n",
    "    # query: batch_size * feature_size\n",
    "    # database.extracted_features: database_size * feature_size\n",
    "    distance_matrix = query.mm(database.extracted_features.t())  # distance_matrix's shape should be batch_size * database_size\n",
    "    top_scores, most_similar_indices = distance_matrix.topk(k)\n",
    "    return top_scores, most_similar_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7f24144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/unittest.status+json": {
       "color": "yellow",
       "message": "",
       "previous": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10])\n",
      "torch.Size([5, 5])\n"
     ]
    },
    {
     "data": {
      "application/unittest.status+json": {
       "color": "lightgreen",
       "message": "..\n----------------------------------------------------------------------\nRan 2 tests in 0.004s\n\nOK\n",
       "previous": 0
      },
      "text/plain": [
       "Success"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.004s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=2 errors=0 failures=0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%unittest_main\n",
    "from vector_search import kNN_search as solution_kNN_search\n",
    "\n",
    "def generate_random_tensor(rng, size):\n",
    "    return torch.tensor(rng.random(size=size))\n",
    "\n",
    "class DummyDatabase(object):\n",
    "    def __init__(self, database_size, feature_size):\n",
    "        rng = np.random.default_rng(10)\n",
    "        self.extracted_features = generate_random_tensor(rng, size=(database_size, feature_size))\n",
    "\n",
    "class TestkNN(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.batch_size = 5\n",
    "        self.feature_size = 32\n",
    "        self.database_size = 128\n",
    "        self.dummy_database = DummyDatabase(self.database_size, self.feature_size)\n",
    "    \n",
    "    def test_kNN_search_k10(self):\n",
    "        random_seed = 0\n",
    "        rng = np.random.default_rng(random_seed)\n",
    "        queries = generate_random_tensor(rng, size=(self.batch_size, self.feature_size))\n",
    "        top_scores, retrieved_indices = kNN_search(queries, self.dummy_database, k=10)\n",
    "        \n",
    "        sol_top_scores, sol_retrieved_indices = solution_kNN_search(queries, self.dummy_database, k=10)\n",
    "        print(retrieved_indices.size())\n",
    "        self.assertTrue(top_scores.equal(sol_top_scores))\n",
    "        self.assertTrue(retrieved_indices.equal(sol_retrieved_indices))\n",
    "        \n",
    "    def test_kNN_search_k5(self):\n",
    "        random_seed = 1\n",
    "        rng = np.random.default_rng(random_seed)\n",
    "        queries = generate_random_tensor(rng, size=(self.batch_size, self.feature_size))\n",
    "        top_scores, retrieved_indices = kNN_search(queries, self.dummy_database, k=5)\n",
    "        \n",
    "        sol_top_scores, sol_retrieved_indices = solution_kNN_search(queries, self.dummy_database, k=5)\n",
    "        print(retrieved_indices.size())\n",
    "        self.assertTrue(top_scores.equal(sol_top_scores))\n",
    "        self.assertTrue(retrieved_indices.equal(sol_retrieved_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d10f8a",
   "metadata": {},
   "source": [
    "### Practice 2: Implement a Simple Flatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fbd8185",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleFlatter(nn.Module):\n",
    "    def forward(self, x):\n",
    "        # x: batch_size * num_channel * img_size * img_size\n",
    "        batch_size = x.size(0)\n",
    "        flatten = x.view(batch_size, -1)  # flatten's shape should be batch_size * (num_channel * img_size * img_size)\n",
    "        return flatten\n",
    "    \n",
    "    def eval(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14ef12da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/unittest.status+json": {
       "color": "yellow",
       "message": "",
       "previous": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/unittest.status+json": {
       "color": "lightgreen",
       "message": ".\n----------------------------------------------------------------------\nRan 1 test in 0.002s\n\nOK\n",
       "previous": 0
      },
      "text/plain": [
       "Success"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%unittest_main\n",
    "from models import SimpleFlatter as SimpleFlatterSolution\n",
    "\n",
    "\n",
    "class TestSimpleFlatter(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.batch_size = 5\n",
    "        self.num_channel = 3  # RGB\n",
    "        self.img_size = 32\n",
    "    \n",
    "    def test_simple_flatter(self):\n",
    "        random_seed = 0\n",
    "        rng = np.random.default_rng(random_seed)\n",
    "        x = generate_random_tensor(rng, size=(self.batch_size, self.num_channel, self.img_size, self.img_size))\n",
    "        model = SimpleFlatter()\n",
    "        out = model(x)\n",
    "        \n",
    "        self.assertTupleEqual((self.batch_size, self.num_channel * self.img_size * self.img_size), out.size())\n",
    "        self.assertTrue(out.equal(x.view(self.batch_size, -1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4744176",
   "metadata": {},
   "source": [
    "## Your First Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e56a86f",
   "metadata": {},
   "source": [
    "### Create Your Database using Flatter and Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e85ef29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 40/40 [00:01<00:00, 24.61it/s]\n"
     ]
    }
   ],
   "source": [
    "flatter = SimpleFlatter()\n",
    "database = Database(testloader, flatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "09ac4447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is you query image!\n",
      "T-shirt/top: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, target, idx = trainset[2]\n",
    "print(\"This is you query image!\")\n",
    "print(f\"{idx_to_class[target]}: {target}\")\n",
    "image_helper.show_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7425122d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The retrieved indices: tensor([[6332, 5437, 3096, 6362, 4587, 6292, 6428, 6314, 3138, 3234]]) (size: (1, 10))\n",
      "Dress: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = img.unsqueeze(0)  # [1, channel_size, img_size, img_size]\n",
    "query = flatter(x)\n",
    "top_scores, indices = kNN_search(query, database)\n",
    "print(f\"The retrieved indices: {indices} (size: {tuple(indices.size())})\")\n",
    "\n",
    "topk = 0\n",
    "retrieved_img, retrieved_label, retrieved_idx = database.get_image_and_target(indices[0][topk])\n",
    "print(f\"{idx_to_class[retrieved_label]}: {retrieved_label}\")\n",
    "image_helper.show_img(retrieved_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79cbb41",
   "metadata": {},
   "source": [
    "### Run All Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "54c75325",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def run_all_retrieval(feature_extractor, valloader, database, k=10):\n",
    "    all_query_labels = []\n",
    "    all_retrieved_indices = []\n",
    "    all_retrieved_labels = []\n",
    "\n",
    "    feature_extractor.eval()\n",
    "    for xs, ys, idxs in tqdm(valloader):\n",
    "        query_features = feature_extractor(xs)\n",
    "        most_similar_indices = kNN_search(query_features, database, k=k)[1]\n",
    "\n",
    "        all_query_labels.extend(ys)\n",
    "        all_retrieved_indices.extend(most_similar_indices)\n",
    "        all_retrieved_labels.extend(database.targets[most_similar_indices])\n",
    "\n",
    "    return torch.stack(all_query_labels), torch.stack(all_retrieved_indices), torch.stack(all_retrieved_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "62737f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 24/24 [00:01<00:00, 18.26it/s]\n"
     ]
    }
   ],
   "source": [
    "query_labels, retrieved_indices, retreived_labels = run_all_retrieval(flatter, valloader, database, k=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a54e5f0d",
   "metadata": {},
   "source": [
    "## How to Evaluate An Image Retrieval System: Mean Average Precision \n",
    "\n",
    "<img src='./resources/map.png' width='75%'  align='left'/><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "20fe186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_precision(label: int, retrieved_labels: np.array, eps=1e-12):\n",
    "    corrects = np.where(retrieved_labels == label, 1, 0)\n",
    "    cum_corrects = np.cumsum(corrects)\n",
    "    denominators = np.arange(1, len(corrects) + 1)\n",
    "    precisions = cum_corrects / denominators\n",
    "    average_prevision = np.sum(precisions * corrects) / (np.sum(corrects) + eps)\n",
    "    return average_prevision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc9aa1b",
   "metadata": {},
   "source": [
    "### Practice 3: Implement Your Own MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f6ae7861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_average_precision(labels, retrieved_labels):\n",
    "    labels, retrieved_labels = labels.cpu().numpy(), retrieved_labels.cpu().numpy()\n",
    "    aps = [average_precision(label, retrieved_ls) for label, retrieved_ls in zip(labels, retrieved_labels)]\n",
    "    aps = np.array(aps)\n",
    "    return np.mean(aps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "17a8dd9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/unittest.status+json": {
       "color": "yellow",
       "message": "",
       "previous": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/unittest.status+json": {
       "color": "lightgreen",
       "message": ".\n----------------------------------------------------------------------\nRan 1 test in 0.002s\n\nOK\n",
       "previous": 0
      },
      "text/plain": [
       "Success"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%unittest_main\n",
    "from metrics import mean_average_precision as solution_map\n",
    "\n",
    "def generate_random_integer_tensor(rng, size, low=0, high=10):\n",
    "    return torch.tensor(rng.integers(low=low, high=high, size=size))\n",
    "\n",
    "class TestmAP(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.batch_size = 5\n",
    "        self.num_classes = 10\n",
    "        \n",
    "    def test_mAP(self):\n",
    "        random_seed = 0\n",
    "        rng = np.random.default_rng(random_seed)\n",
    "        k = 10\n",
    "        \n",
    "        labels = generate_random_integer_tensor(rng, size=self.batch_size, high=self.num_classes)\n",
    "        retrieved_lables = generate_random_integer_tensor(rng, size=(self.batch_size, k), high=self.num_classes)\n",
    "        mean_ap = mean_average_precision(labels, retreived_labels)\n",
    "        \n",
    "        self.assertEqual(mean_ap, solution_map(labels, retreived_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f19d5bc",
   "metadata": {},
   "source": [
    "### Evaluate Simple Flatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "25baf097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Flatter's mAP: 0.7145059694663739\n"
     ]
    }
   ],
   "source": [
    "s_map = mean_average_precision(query_labels, retreived_labels)\n",
    "print(f\"Simple Flatter's mAP: {s_map}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3851ad23",
   "metadata": {},
   "source": [
    "### Improve Simple Flatter: Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1724e505",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizedSimpleFlatter(nn.Module):\n",
    "    def forward(self, x):\n",
    "        # x: batch_size * num_channel * img_size * img_size\n",
    "        batch_size = x.size(0)\n",
    "        flatten = x.view(batch_size, -1)  # flatten's shape should be batch_size * (num_channel * img_size * img_size)\n",
    "        return F.normalize(flatten)\n",
    "    \n",
    "    def eval(self):\n",
    "        pass\n",
    "    \n",
    "normed_flatter = NormalizedSimpleFlatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "71a0836d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 40/40 [00:01<00:00, 25.93it/s]\n"
     ]
    }
   ],
   "source": [
    "normed_database = Database(testloader, normed_flatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ef3cc1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 24/24 [00:01<00:00, 18.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Flatter's mAP: 0.8339065517656489\n"
     ]
    }
   ],
   "source": [
    "query_labels2, retrieved_indices2, retreived_labels2 = run_all_retrieval(normed_flatter, valloader, normed_database, k=10)\n",
    "print(f\"Normalized Flatter's mAP: {mean_average_precision(query_labels2, retreived_labels2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02f04e6",
   "metadata": {},
   "source": [
    "## Deep Learning Based Image Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "974dd15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import FeatureExtractor, Classifier\n",
    "from torch.optim import Adam\n",
    "\n",
    "feature_extractor = FeatureExtractor()\n",
    "classifier = Classifier()\n",
    "model = nn.Sequential(feature_extractor, classifier)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f5efa215",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [00:09<00:00, 22.73it/s]\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 27.93it/s]\n",
      "  1%|▌                                          | 3/211 [00:00<00:08, 23.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, val_loss: 1.174, Accuracy: 80.000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [00:08<00:00, 23.46it/s]\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 28.08it/s]\n",
      "  1%|▌                                          | 3/211 [00:00<00:09, 22.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, val_loss: 0.709, Accuracy: 84.667\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [00:09<00:00, 22.93it/s]\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 27.92it/s]\n",
      "  1%|▍                                          | 2/211 [00:00<00:10, 19.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, val_loss: 0.499, Accuracy: 87.567\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [00:09<00:00, 22.99it/s]\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 27.64it/s]\n",
      "  1%|▌                                          | 3/211 [00:00<00:09, 22.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, val_loss: 0.394, Accuracy: 89.400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [00:09<00:00, 23.26it/s]\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 28.46it/s]\n",
      "  1%|▌                                          | 3/211 [00:00<00:09, 23.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, val_loss: 0.334, Accuracy: 90.717\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [00:09<00:00, 23.23it/s]\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 28.01it/s]\n",
      "  1%|▌                                          | 3/211 [00:00<00:09, 22.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, val_loss: 0.303, Accuracy: 90.600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [00:09<00:00, 22.98it/s]\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 28.06it/s]\n",
      "  1%|▌                                          | 3/211 [00:00<00:08, 23.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, val_loss: 0.287, Accuracy: 90.667\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [00:09<00:00, 23.36it/s]\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 28.36it/s]\n",
      "  1%|▌                                          | 3/211 [00:00<00:09, 23.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, val_loss: 0.269, Accuracy: 91.267\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [00:09<00:00, 23.30it/s]\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 28.42it/s]\n",
      "  1%|▌                                          | 3/211 [00:00<00:09, 22.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, val_loss: 0.259, Accuracy: 91.150\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [00:09<00:00, 23.15it/s]\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 27.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, val_loss: 0.255, Accuracy: 91.100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from trainers import train\n",
    "\n",
    "epoch = 10\n",
    "model = train(model, optimizer, trainloader, valloader, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2cc186e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 40/40 [00:03<00:00, 10.77it/s]\n",
      "100%|███████████████████████████████████████████| 24/24 [00:02<00:00, 10.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Extractor's mAP: 0.9131850488419626\n"
     ]
    }
   ],
   "source": [
    "deep_database = Database(testloader, feature_extractor)\n",
    "\n",
    "query_labels3, retrieved_indices3, retreived_labels3 = run_all_retrieval(feature_extractor, valloader, deep_database, k=10)\n",
    "deep_map = mean_average_precision(query_labels3, retreived_labels3)\n",
    "print(f\"Deep Feature Extractor's mAP: {deep_map}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec6f48b",
   "metadata": {},
   "source": [
    "## Compare the Image Retrieval Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "62eeca09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flatters database size: 10240000\n",
      "Deep database size: 1280000\n",
      "\n",
      "The deep learning based system is 8x smaller,\n",
      "while it's mAP is 27.81% better even on this simple dataset.\n"
     ]
    }
   ],
   "source": [
    "print(f'Flatters database size: {database.extracted_features.numel()}')\n",
    "print(f'Deep database size: {deep_database.extracted_features.numel()}')\n",
    "print()\n",
    "print(f'The deep learning based system is {int(database.extracted_features.numel() / deep_database.extracted_features.numel())}x smaller,')\n",
    "print(\"while it's mAP is {:.2f}% better even on this simple dataset.\".format((deep_map - s_map) / s_map * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c02f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
